{% extends "base.html" %}

{% block title %}Record - Speech Summary App{% endblock %}

{% block head %}
<link rel="stylesheet" href="{{ url_for('static', filename='css/record.css') }}">
{% endblock %}

{% block content %}
<div class="record-page">
    <h2>Record Your Speech</h2>
    
    <div class="recording-container">
        <!-- Step Navigation -->
        <div class="steps-nav">
            <div class="step-indicator active" id="step-indicator-1">
                <div class="step-number">1</div>
                <div class="step-label">Setup</div>
            </div>
            <div class="step-indicator" id="step-indicator-2">
                <div class="step-number">2</div>
                <div class="step-label">Record</div>
            </div>
            <div class="step-indicator" id="step-indicator-3">
                <div class="step-number">3</div>
                <div class="step-label">Process</div>
            </div>
            <div class="step-indicator" id="step-indicator-4">
                <div class="step-number">4</div>
                <div class="step-label">Results</div>
            </div>
        </div>
        
        <!-- Step 1: Setup -->
        <div id="step-1" class="step active">
            <h3>Set Up Your Recording</h3>
            <form id="recording-setup-form" method="POST">
                <div class="form-group">
                    <label for="recording-title">Recording Title:</label>
                    <input type="text" id="recording-title" name="recording-title" placeholder="Enter a descriptive title for your recording" required>
                </div>
                <button type="submit" class="btn btn-primary">
                    <i class="fas fa-microphone"></i> Start Recording
                </button>
            </form>
        </div>
        
        <!-- Step 2: Recording in Progress -->
        <div id="step-2" class="step">
            <h3>Recording in Progress</h3>
            <div class="record-status">
                <div class="record-indicator">
                    <div class="record-pulse"></div>
                </div>
                <p><i class="fas fa-circle"></i> Recording... <span id="recording-time">00:00</span></p>
            </div>
            
            <div class="live-transcript">
                <h4><i class="fas fa-file-alt"></i> Live Transcript:</h4>
                <div id="transcript-container">
                    <p id="transcript-text">
                        <span id="final-transcript"></span>
                        <span id="interim-transcript" class="interim-text"></span>
                    </p>
                </div>
            </div>
            
            <div class="recording-controls">
                <button id="stop-recording-btn" class="btn btn-danger">
                    <i class="fas fa-stop"></i> Stop Recording
                </button>
            </div>
        </div>
        
        <!-- Step 3: Processing -->
        <div id="step-3" class="step">
            <h3>Processing Your Recording</h3>
            <div class="processing-status">
                <div class="loader"></div>
                <p>Analyzing speech patterns...</p>
                <p class="processing-info">Our AI is processing your recording to create a transcript and generate a summary.</p>
            </div>
        </div>
        
        <!-- Step 4: Results -->
        <div id="step-4" class="step">
            <h3>Recording Results</h3>
            <div class="results-container">
                <div class="summary-section">
                    <h4><i class="fas fa-clipboard-check"></i> Summary:</h4>
                    <div id="summary-text" class="result-box">
                        <!-- Will be filled with summary from backend -->
                    </div>
                </div>
                
                <div class="transcript-section">
                    <h4><i class="fas fa-file-alt"></i> Full Transcript:</h4>
                    <div id="full-transcript-text" class="result-box">
                        <!-- Will be filled with the complete transcript -->
                    </div>
                </div>
            </div>
            
            <div class="finish-buttons">
                <a href="{{ url_for('home') }}" class="btn btn-secondary">
                    <i class="fas fa-home"></i> Back to Dashboard
                </a>
                <a href="{{ url_for('record_new') }}" class="btn btn-primary">
                    <i class="fas fa-microphone"></i> Record Another
                </a>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Step elements
        const steps = document.querySelectorAll('.step');
        const stepIndicators = document.querySelectorAll('.step-indicator');
        
        // Form elements
        const recordingSetupForm = document.getElementById('recording-setup-form');
        const recordingTitle = document.getElementById('recording-title');
        
        // Recording elements
        const stopRecordingBtn = document.getElementById('stop-recording-btn');
        const recordingTime = document.getElementById('recording-time');
        const finalTranscript = document.getElementById('final-transcript');
        const interimTranscript = document.getElementById('interim-transcript');
        const fullTranscriptText = document.getElementById('full-transcript-text');
        const summaryText = document.getElementById('summary-text');
        
        // Global variables
        let timer;
        let seconds = 0;
        let minutes = 0;
        let completeTranscript = '';
        
        // Speech recognition setup
        let recognition = null;
        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            
            recognition.onresult = function(event) {
                let interim = '';
                let final = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    
                    if (event.results[i].isFinal) {
                        final += transcript + ' ';
                        completeTranscript += transcript + ' ';
                    } else {
                        interim += transcript;
                    }
                }
                
                // Update the transcript displays
                if (final) {
                    finalTranscript.textContent += final;
                }
                interimTranscript.textContent = interim;
                
                // Auto scroll to bottom of transcript container
                const container = document.getElementById('transcript-container');
                container.scrollTop = container.scrollHeight;
            };
            
            recognition.onerror = function(event) {
                console.error('Speech recognition error:', event.error);
                // Handle errors gracefully
                if (event.error === 'not-allowed') {
                    alert('Microphone access denied. Please enable microphone access to use this feature.');
                    goToStep(1);
                }
            };
        } else {
            alert('Speech recognition is not supported in this browser. Please try using Chrome or Edge.');
        }
        
        // Functions
        function goToStep(stepNumber) {
            // Hide all steps and update indicators
            steps.forEach((step, index) => {
                step.classList.remove('active');
                stepIndicators[index].classList.remove('active', 'completed');
            });
            
            // Show the current step
            document.getElementById(`step-${stepNumber}`).classList.add('active');
            
            // Update step indicators
            for (let i = 0; i < stepNumber; i++) {
                stepIndicators[i].classList.add('completed');
            }
            stepIndicators[stepNumber - 1].classList.add('active');
        }
        
        function updateTimer() {
            seconds++;
            if (seconds >= 60) {
                seconds = 0;
                minutes++;
            }
            
            recordingTime.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        }
        
        function startTimer() {
            timer = setInterval(updateTimer, 1000);
        }
        
        function stopTimer() {
            clearInterval(timer);
        }
        
        // Start the recording
        function startRecording() {
            // Request microphone access
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    // Start the timer
                    startTimer();
                    
                    // Start speech recognition
                    if (recognition) {
                        recognition.start();
                    }
                    
                    // Move to recording step
                    goToStep(2);
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                    alert('Could not access microphone. Please ensure you have granted permission.');
                });
        }
        
        // In the stopRecording function, add a check for short transcripts
        function stopRecording() {
            // Stop the speech recognition
            if (recognition) {
                recognition.stop();
            }
    
            // Stop the timer
            stopTimer();
    
            // Move to processing step
            goToStep(3);
    
            // Check if transcript is too short (for testing purposes)
            if (completeTranscript.trim().length < 50) {
                console.log("Transcript is very short. Backend may use a test transcript instead.");
            }
    
            // Send to the backend for summarization
            fetch('/summarize-transcript', {
                method: 'POST',
                body: new URLSearchParams({
                    'title': recordingTitle.value,
                    'transcript': completeTranscript
                }),
                headers: {
                    'Content-Type': 'application/x-www-form-urlencoded'
                }
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Server returned status: ' + response.status);
                }
                return response.json();
            })
            .then(data => {
                console.log('Recording processed:', data);
        
                // Show the full transcript and summary in the results
                fullTranscriptText.textContent = completeTranscript;
        
                if (data.summary) {
                    summaryText.textContent = data.summary;
                } else {
                    summaryText.textContent = "No summary available.";
                }
        
                // Move to results step
                goToStep(4);
            })
            .catch(error => {
                console.error('Error processing recording:', error);
                alert('An error occurred while processing the recording: ' + error.message);
        
                // Still go to results but show error
                fullTranscriptText.textContent = completeTranscript;
                summaryText.textContent = "Error generating summary: " + error.message;
                goToStep(4);
            });
        }
        
        // Event Listeners
        recordingSetupForm.addEventListener('submit', function(e) {
            e.preventDefault();
            
            const title = recordingTitle.value;
            if (!title) {
                alert('Please enter a title for your recording');
                return;
            }
            
            // Reset transcript and recording variables
            finalTranscript.textContent = '';
            interimTranscript.textContent = '';
            completeTranscript = '';
            seconds = 0;
            minutes = 0;
            
            // Start the recording process
            startRecording();
        });
        
        stopRecordingBtn.addEventListener('click', function() {
            stopRecording();
        });
    });
</script>
{% endblock %}